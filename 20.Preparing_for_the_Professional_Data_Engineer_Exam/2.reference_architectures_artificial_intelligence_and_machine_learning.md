## Resources 

- [Learn Tensorflow](https://www.tensorflow.org/learn) 

## Lesson Transcript
```text
Hello, Cloud Gurus.
In this video, we'll continue our discussion
of Google's official published reference architectures
by looking at solutions for AI and machine learning.
So back on the GCP Solutions website,
let's take a look at the reference architectures
for AI and ML,
which are also in the Smart Analytics section.
First, we'll take a look at recommendation engines,
a common AI implementation in the retail industry.
I'm hoping that you've gathered from this course
that as a data engineer,
you can appraise a design like this
and understand all of the moving parts
without needing to be a data scientist
or machine learning expert yourself.
These are all components we're familiar with
and we know how they fit together.
In this solution, we have various data sources we can use,
including inventory data,
purchases, customer wishlists, and reviews.
We can set up an ETL pipeline using Cloud Dataflow
to ingest and transform all of this data,
then combine and normalize it for storage in our Data Lake
in Cloud Storage.
From here, we can assume that our data analysts
are comfortable with Spark and MLlib,
so they can begin to develop these models
with Cloud Dataproc.
Trained ML models can then be hosted with Cloud ML Engine
and served using the prediction API
that is part of AI Platform.
Our retail applications
can then make use of this trained model
to make recommendations to customers shopping on our site.
Because the model has been trained
on all of the browsing history, previous purchases,
reviews, wishlists, and likes of our customers
and other customers that match them in various demographics,
our site will have a higher chance of recommending products
that are actually likely to be added to their shopping cart.
In a nutshell, this is basically how Amazon works.
For further historical analytics
and to help build the next generation of model,
we also export all of the uses
of our trained model to BigQuery.
Okay, we don't need to get too into the weeds
of AI and ML for this cert,
but let's look at one more as it's quite interesting.
Semantic similarity.
The metric of semantic similarity can be used to measure
how similar documents are in their meaning
or semantic content.
A very simplistic explanation of the concept could be this.
Rather than just comparing documents
to see if they contain the same words,
all of the words in each document
are evaluated mathematically using a model
that understands the semantic relationships
between words based on comparisons of taxonomy or concept.
Okay, maybe that's not very simplistic.
Let's get back to the diagram.
In terms of actual infrastructure,
this solution is very simple.
Our Data Lake once again is Cloud Storage,
where we store all of our raw text documents.
The features of our texts
are extracted by a Cloud Dataflow pipeline.
And this could be continually streaming through
or triggered by Cloud Pub/Sub.
The pipeline uses TensorFlow modules
to annotate the documents with embeddings,
kind of like scoring for their similarity.
Then the annotated articles are pushed into BigQuery
for later analysis using SQL queries.
Again, this is another great example
where if you don't understand
the machine learning science part of this,
that's perfectly okay.
You're the data engineer.
You just need to know what parts to put together
to make this work.
Okay, Cloud Gurus, we'll leave it there.
But again, I'd encourage you to browse
through the other solutions in your own time.
Join me in the next video
where we'll look at some of the reference architectures
for internet of things systems.
```

## Lesson Transcript
```text
Hello, Cloud Gurus.
Welcome to this chapter where we'll take an in-depth
look at Google's Cloud Dataproc.
Before we get started, if for any reason you've skipped
the chapter on Hadoop, please go back and watch that now.
You'll need to have covered the concepts
from that chapter before we move on to this one.
Still with me?
Great.
Then let's get started.
So what is Cloud Dataproc?
And why did I want to make sure you'd completed
the Hadoop chapter?
Essentially, Cloud Dataproc is a managed cluster service
in GCP for running Hadoop and Spark jobs.
It takes away all of the hassle of running your own clusters
and VMs, and managing storage,
and sets up a managed service
that's ready to accept jobs that you simply send to it.
Why would you want to use a managed service?
Well, if you recall from the Hadoop chapter,
in the demos, I didn't show you all the behind
the scenes toil of getting the Hadoop
and spark services up and running.
There's a lot involved in this.
You need to provision machines, giving considerations
to things like CPU, RAM, and disk sizing.
Then install all the necessary software.
And then configure these machines
to set up a working cluster.
You could argue that even though that's a lot of work,
it's just a one-off effort.
But what if you need to grow your cluster
to handle a larger workload or dataset?
And what about all the times your cluster isn't busy?
It's just sat there, incurring costs
for all those wasted resources.
That's why in general, in the cloud,
managed services are always preferable.
Cloud Dataproc provides managed clusters
for Spark and Hadoop.
Using parameters you define it will create
a master node, running the YARN resource manager
and HDFS named node, and worker nodes,
running the yarn node manager and HDFS data nodes.
Each node comes automatically pre-installed
with a recent stable version of Hadoop and Spark,
as well as Zookeeper, Apache Hive, Pig, and Tez,
and other tools such as Jupyter Notebooks,
and a GCS connector.
There are also additional components that can be added,
or you can even create a custom image
to be deployed to the VMs in your Dataproc cluster.
All of the cluster and storage configuration
is handled for you by the Dataproc service.
Now, before we move on, let's take a moment
to appreciate the graphic artists.
Who've worked so hard on all these lovely product logos.
The most compelling feature of Dataproc,
as a managed service, is its billing model.
Standing up a cluster ready to accept jobs
takes about 90 seconds and cluster resources
are billed per second with a minimum billing period
of just 1 minute.
This means you can quickly set up resources
to process a dataset or scale up an existing cluster
when you're expecting a larger than normal workload,
then scale it down again,
or even turn it off and only pay for what you use.
Once your cluster is up and running,
you simply submit Hadoop or Spark jobs to it,
as you would with any other Hadoop or Spark service.
Dataproc is completely interoperable and compatible
with up-to-date versions of these open source tools.
If necessary, the cluster can be designed
to auto scale, to cope with the load of the job.
Outputs can be automatically pushed
to Google Cloud Storage, BigQuery, and BigTable.
And Dataproc also integrates
with Stackdriver logging and monitoring.
Okay Cloud Gurus, now you know what Dataproc is.
Join me in the next video where we'll learn
how to set up a cluster and submit some jobs.

```

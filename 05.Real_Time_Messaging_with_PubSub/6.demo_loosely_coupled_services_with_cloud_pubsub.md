## Resources 
- [main.py](resources%2Fmain.py)
- [requirements.txt](resources%2Frequirements.txt)

## Lesson Transcript
```text
Hello, Cloud Gurus and welcome to this lab:
Loosely Coupled Services with Cloud Pub/Sub.
The purpose of this lab is to demonstrate
how Pub/Sub can be used as a logical glue
to loosely couple services together,
either in synchronous or asynchronous workflows.
To do this, we'll create a Cloud Storage
notification configuration that publishes messages
to a Pub/Sub topic.
And we'll create a Cloud Function
with a push subscription trigger.
Here's the architecture we're going to try to simulate.
We're hosting an imaginary website
that allows users to upload images,
and we want to create a thumbnail image
every time they do so.
The initial image gets written to a Cloud Storage bucket,
and this triggers a notification in the form of a message
that gets published to our notification topic.
We then have a Cloud Function,
which receives a push notification from our topic.
The Cloud Function will fire up, create a thumbnail image,
and write it to another Cloud Storage bucket.
This example of loose coupling
allows us to separate the generation of thumbnail images
from our main application
so it's not blocking while this takes place.
Processing images is more compute intensive
than the rest of our application.
So it's great that we can scale this component up and down
on its own through Cloud Functions
using Pub/Sub to join everything together.
Now in this lab,
to save us the trouble of creating an actual website,
we'll just drop the initial images
into the Cloud Storage bucket manually.
To follow along with this lab,
you'll need your own GCP project.
And inside that project,
we'll do all our work with the Cloud Console,
Cloud Shell, and the Cloud Shell editor.
You'll also need some images to use for testing purposes.
Any images will do
as long as they're not already thumbnail sized.
Once you've got those at hand, join me in your GCP project.
So here we are once again in our GCP console.
The first thing to do
is create our Pub/Sub notification topic.
So let's go to Pub/Sub in the menu,
click Create Topic,
and we'll call this topic newImage with a capital I.
Now let's go to Cloud Storage
and create the 2 GCS buckets we'll need,
one for images and one for thumbnails.
Click Create Bucket.
Remember that bucket names exist in a global namespace,
not just in your project,
so I recommend using your project name
as a prefix for bucket names.
So I'm going to call my first bucket tim-acloud-guru-images.
We can accept all the defaults and just click Create.
Then go back, click Create Bucket again.
And this time, I'll create a bucket
called tim-acloud-guru-thumbnails
and click Create.
Click back again
and here we can see our 2 new GCS buckets.
Now we need to open the Cloud Shell.
We're going to use gsutil,
the command line tool for Google Cloud Storage,
to add a notification configuration to our images bucket.
Now technically, Cloud Storage
can actually trigger functions directly,
but we just want events in our bucket
to publish messages to Pub/Sub,
partly because this is a Pub/Sub lab
and partly because by decoupling with Pub/Sub,
we could use any component we like
as a subscriber to those messages,
like a compute VM or a container, not just a function.
Okay, so let's run this command,
gsutil notification create,
to create the new configuration,
f json,
this specifies that our message
should contain a JSON payload,
e OBJECT_FINALIZE,
this limits the events in our bucket
that will trigger a message
to just the type object finalize,
which will happen when a new image has been written.
We don't want a message
for every single event in our bucket.
t and the full topic path.
This starts with projects/ your project name
/topics
/ the topic name,
and finally, the Google storage URL of your bucket,
which is just the bucket name prefixed with gs://.
The command wraps around as it's so long,
but this is just my image's bucket name.
The command returns by telling us
that our notification config has been created.
Okay, time to write our Cloud Function.
We'll do this with the Cloud Shell Editor.
You can download the files I'm about to write
from the resources section as after all,
we're here to learn Pub/Sub, not Python,
but you will need to make one change,
and it will be useful to talk you through the code
as we go anyway.
First, we'll create a new directory for our function,
which we'll call gen_thumbnail.
Let's change into that directory.
In this directory, let's create a new file called main.py.
We start by importing some libraries we need,
wand for images and the Google Cloud Storage library.
Then we create a client that connects to Cloud Storage
and we hard-code the name of our thumbnails bucket
just for simplicity.
Our gen_thumbnail method receives the payload from Pub/Sub
and stores it in the variable data.
From this, we extract the name of the bucket and image
and create a new name for our thumbnail image.
Then we connect to the GCS client
and download the image into memory.
Next, we use the image library we loaded
to create a new version of the image at 300x300 pixels.
Then we switch to our thumbnails bucket
and upload the new thumbnail image.
Before we finish, just make sure you've changed this
to the name of your thumbnails bucket in the script,
not your main image bucket.
If you accidentally use the main images bucket,
when we deploy our function,
we'll start a recursive loop of thumbnails
being created from thumbnails being created from thumbnails.
It'll be thumbception and no one wants that.
Okay, let's save that file.
Now we just need one more file called requirements.txt.
This file tells the Cloud Function's runtime
which Python libraries are required.
In our case, that's just google-cloud-storage and wand.
Save that file and jump back into the terminal.
Now we can deploy our function
with gcloud functions deploy gen_thumbnail
-runtime python37
-trigger-topic newImage.
So here we're just deploying our function
specifying the runtime it will use,
and the name of the Pub/Sub topic
that should trigger its invocation.
Thankfully, we can just put the topic name on its own.
We don't have to use the full topic path.
Here, we'll accept the default of no
for accepting unauthenticated invocations
as our function is not a public HTTP service.
And then GCloud will deploy our function.
This can take a few minutes
the first time you deploy a new function,
so pause the video here
while you wait for your command to complete.
Let's take a look at our deployed function.
Under the Trigger tab, we can see the topic we specified.
Let's click on that topic to take us to the Pub/Sub section.
Now, if we go to our subscriptions,
we can see that deploying our function
has created a push subscription that's associated with it.
So now let's test our function
by uploading some images to our bucket.
We'll go to the Cloud Storage browser
and into our images bucket.
Upload an image from your computer into the bucket
and click on the filename
to look at the details of the image.
We'll open the object link in a new tab
just so we can see the size of the original image.
Now let's go back to our thumbnails bucket
and see if our Cloud Function worked.
And here's our thumbnail image.
We can open the link in a new tab
to see that it is indeed a much smaller picture.
The aspect ratio is off and the re-sampling is bad,
but we could probably have done some math
to fix these things in our script.
But again, we're just here to see what Pub/Sub can do.
The message was sent, which notified our function,
which generated the thumbnail.
Let's upload one more image.
We'll go back to our images bucket
and upload another image from our computer,
then check in the thumbnails bucket,
and here it is.
We can look at our Cloud Function
and see a graph showing all of its invocations.
If we look at the trigger again
and click through to our Pub/Sub topic,
we can just about see the graph of messages
roughly matches the Cloud Functions graph.
Obviously, this is a really simple example,
but it should hopefully start you thinking
about how you can break up services
that used to talk directly to each other
and add the buffer that Pub/Sub can provide between them.
To clean up from this lab, just delete your Pub/Sub topic,
then go into Cloud Functions and delete your function.
And finally, delete your two GCS buckets.
Great job, Cloud Gurus.
If you have any questions about this lab,
please feel free to ask me in the course forum.
And if not, I'll see you in the next video.

```

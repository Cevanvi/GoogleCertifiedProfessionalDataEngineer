## Lesson Transcript
```text
Welcome back Gurus.
In this chapter, we'll be covering
some of the core capabilities
in the language AI building block.
So the 2 aspects of language
are translation and natural language.
Translation allows you to detect languages
as well as translate between them.
Natural language allows you to uncover structure
and meaning within free text.
When translating,
you are able to specify a source language.
For this example,
our source language is French.
Of course, we always need to specify a target language.
Let's go with English.
And it's pretty simple,
Je t'aime beaucoup is translated to,
I love you so much.
You don't necessarily have to specify the source language.
It can automatically be detected.
The input text can be plain text or HTML.
By default, when you make a translation request,
your text is translated using
the neural machine translation model
or NMT model.
The NMT model is not supported for all languages.
If it is not supported,
then the phrase based machine translation model is used.
That's also known as the PBMT model.
The NMT model generally provides better translation
for longer and for more complex text.
You can always specify that you want
the PBMT model to be used.
Now the natural language capability is able
to uncover structure and meaning within free text.
As an example,
let's consider a segment of a movie review.
The movie was incredible.
I really enjoyed the fast-paced action scenes
that ranged from the streets of Paris
to the Tundra of Alaska.
The language API is able to perform a number
of analyses on this texts.
So it's able to perform sentiment analysis,
entity analysis, syntax analysis,
entity-sentiment analysis.
It's also able to classify the content of the text.
Let's look at each of these in turn in more detail.
Let's start with sentiment analysis.
The score of a document sentiment indicates the overall
positive or negative emotionality
that is expressed within the text.
The sentiment score is a number
which ranges between -1 for negative
and +1 for positive.
Then there is the magnitude.
The magnitude attempts to express how much emotional content
is present within the document.
The magnitude ranges between 0 and infinity.
Unlike score, the magnitude is not normalized.
As a result of this,
the magnitude value is often proportional
to the length of the documents.
So a long positive article will tend to have a greater
positive magnitude, than a shorter positive article.
It's also important to note that the natural language API
does not distinguish between different types of emotion,
such as happy or sad.
There are only 2 categories,
positive and negative.
So in the response shown here,
the score is 8 and the magnitude is 3.
On the right are a few additional examples.
So text that is clearly positive,
text that is clearly negative, text that is somewhat neutral
or unemotional
and finally texts that has
a mixture of positive and negative sentiment.
Entity analysis identifies entities within the text.
It then provides information on the entities
that have been identified.
Entities are nouns or things that are detected
such as people, places, objects, et cetera.
Because entities are nouns they are off 2 types,
proper nouns and common nouns.
Proper nouns tend to map to specific things.
For example, the name Albert Einstein
maps to the man, Albert Einstein.
Common nouns, such as "mug" could map to any mug.
So what we have depicted here is an example,
entity analysis response.
It contains the name of the entity, the entity type.
This is not the broad categorization
into proper and common nouns.
Next we have the machine generated ID
or the unique ID for the entity.
There is a Wikipedia URL, if it is identified.
The salience indicates the importance of this entity
to the entire text that was submitted.
Mentions indicates offset positions,
where the entity was mentioned within the text.
As expected, Britain is a proper noun.
Now, entity sentiment analysis,
combines entity analysis and sentiment analysis.
It tries to determine the sentiment expressed in the text
towards each of the entities that were identified.
So imagine you were examining text about someone
who listened to 2 albums and provided feedback.
They loved the first, but didn't really enjoy the second.
Clearly we would expect there to be different sentiments
linked to each of the albums.
Entity sentiment analysis tries to capture this.
Entity sentiment is represented
by a numerical score
and magnitude values,
and it is determined for each mention of the entity,
just as we had with sentiment analysis.
The scores are then aggregated into an
overall sentiment score and magnitude for each entity.
Aggregation makes sense where the entity is mentioned
multiple times within different contexts.
In this example response,
we have R and B music with a sentiment magnitude of 0.9,
as well as a sentiment score of 0.9.
Syntax analysis allows for the pausing of text
for syntax analysis.
Sentence extraction breaks up the stream of text
into a series of sentences.
Tokenization will break the stream of text
into a series of tokens.
The sentences and tokens are used
to determine grammatical information.
Examples of grammatical information would include
parts of speech, such as subject, object,
verb, plurals, singulars, etc.
Finally, let's look at content classification.
You can have the natural language API analyze a document
and return a list of content categories
that apply to the text within the document.
These predefined categories exist
in a hierarchical structure.
The API will return the categories that are most specific.
It's important to note that more than
one category can be assigned to the content.
Okay, that's it for the video on language.
I hope you found this video interesting,
and that you have some ideas
about how the language AI building block
could be used in your organization.
See you in the next video.
```

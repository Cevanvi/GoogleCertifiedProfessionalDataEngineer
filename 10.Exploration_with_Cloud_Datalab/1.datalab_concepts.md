## Resources 

- [Vertex AI Workbench - provides features beyond Datalab](https://cloud.google.com/vertex-ai/docs/workbench/introduction) 

## Lesson Transcript
```text
Hello, Cloud Gurus.
In this mini chapter,
we'll take a quick look at Cloud Datalab,
an interactive tool for data exploration,
analysis, visualization, and machine learning.
As is traditional now, let's start by asking,
what is Cloud Datalab?
Well, it's a bit of an outlier for GCP services
because it's basically a preexisting technology
that gets wrapped in some GCP conveniences.
That preexisting technology is called Jupyter Notebooks.
So really we need to ask, what are Jupyter Notebooks?
Well, you can think of Jupyter Notebooks
as interactive webpages.
At first glance,
they look a bit like a web-based text editor,
and in some ways they are,
but rather than just containing text,
Jupyter Notebooks can contain documentation, code,
and most importantly,
elements which are the results of compiled code.
These elements could include graphs, visualizations,
or just the results of some mathematical calculation.
So that's a rather broad concept to just throw out there.
Let's visualize what we're talking about.
Here's what a simple notebook might look like.
I can add some text
to explain what my notebook is all about,
but then here's the clever part.
I can also add some Python code right inside the notebook,
and then I can actually run that code
and the results will be displayed inside my notebook.
When you open a notebook,
something called a kernel process is launched
on the VM hosting the notebook.
Don't confuse this with a Linux kernel.
They just share the same name.
This kernel can execute code within the notebook
and access GCP services like BigQuery or ML Engine.
Everything you do while working on your notebook
exists within a session run on this kernel.
So outputs from one section of code
can be used in the next section of code.
Because of the mixed media support in Jupyter Notebooks,
they are a fantastic way
to share and collaborate on information.
Rather than just presenting outputs or data,
you can annotate and describe data in context
as it's presented.
For example, here is a BigQuery query
and its result rendered in the document.
Jupyter Notebooks have built-in support
for a variety of Python graphing and plotting libraries.
One of the most commonly used is Matplotlib.
It's easy to see why Jupyter has become very popular
in the sciences as these notebooks
are almost like interactive academic journals.
You can easily share notebooks with other people,
allowing them to run calculations for themselves
with their own instance of the notebook.
Cloud Datalab configures a Google Source Repository
for your notebooks,
which is automatically cloned onto the persistent disk
attached to your Datalab instance.
So if Jupyter Notebooks are so great on their own,
why do we need Cloud Datalab?
Well, as I said at the start, it's all about convenience.
Google's Datalab command line tool
manages the lifecycle of a Datalab instance,
which hosts your notebooks and kernel processes.
It can quickly create a Datalab VM in seconds
without you having to worry about downloading, installing,
and configuring the correct software.
As we've seen, Datalab creates the Git repo
for your notebooks in Google Cloud Source Repositories,
which is then cloned onto the persistent disk
of the Datalab instance.
Changes to notebooks can then be committed back to the repo.
You can also safely delete a Datalab instance
while retaining its persistent disk.
You can then use the existing disk
when you create a new Datalab instance.
Okay, Cloud Gurus,
I think we've reached peak brain theory input again,
so let's get hands-on with a Cloud Datalab lab.

```

## Resources

- [About the course](https://drive.google.com/file/d/1coNuJvlG9vK1jsFYLfIWLEMSeIgnmdNe/view)

## Lesson Transcript
```text
Hello, Cloud Gurus and welcome to the course.
My name is Tim Berry. And in this video,
I'm going to tell you all about the structure
of the course itself and how it will help you
become a certified Google professional data engineer.
In a nutshell, this course is all about
learning to be a data engineer.
But what is a data engineer?
Well, according to Google's own specification
for this certification,
a data engineer should be able to design, build,
operationalize, secure, and monitor data processing systems
with a particular emphasis on security and compliance,
scalability and efficiency, reliability and fidelity,
and flexibility and portability.
Wow, that's a lot of -ility words.
In plain English, this qualification is all about
being able to effectively choose the right products
and services in GCP, and then implement them correctly.
Whether that's to deal with big data analytics
or machine learning,
or just leveraging Google's existing APIs.
This course is going to break down
everything you need to know in manageable chunks.
The first chapter of the course is the introduction,
which you're already in. So great start!
In a moment I'll go over the intended audience
for this course, some prerequisites,
and what to expect from the exam itself.
Next, we'll look at some of the fundamentals
of data processing, big data concepts,
and a high level overview of the stages of a data pipeline,
ingestion, storage, processing, and visualization.
Then we'll take a tour of the storage and database options
available to us in GCP, both structured and unstructured,
including SQL and NoSQL databases.
Before we deep dive on any of the GCP products themselves,
we'll start by quickly familiarizing ourselves
with the wider, big data ecosystem.
We'll look at the origins of MapReduce, Hadoop, and HDFS
and common Apache big data tools like Pig, Spark, and Kafka.
Knowing how these technologies mapped
to their equivalent services in GCP
is a big part of the exam.
Next we'll look at Pub/Sub,
which is often the first tool we use in a big data pipeline.
Pub/Sub is Google's fully managed message bus
that can handle millions of messages a second.
Then we'll move on to data flow,
a serverless implementation of Apache Beam
for streaming data pipelines.
A lot of Google's big data products are geared towards
helping organizations lift and shift existing workloads
into the cloud.
So next we'll look at Cloud Dataproc, a managed service
for running Apache Spark clusters and jobs.
Then we'll start looking at some of the advanced bespoke
data services Google offers starting with Bigtable,
a massively performant wide column,
NoSQL database for time series data.
Then we'll move on to BigQuery Google's jewel
in the big data crown.
It's their petabyte scale data warehouse,
which now even offers machine learning with BigQuery ML.
Once we've ingested and processed our data,
it's time to start visualizing it.
We'll play with Jupyter notebooks in Cloud DataLab,
helping us to interact with data and run analytics
and machine learning jobs from right inside our browser.
Then we'll move on to Data Studio, a data visualization tool
that helps you turn your data into business intelligence
with interactive dashboards and reports.
Finally, in our big data lineup,
we'll look at Cloud Composer, a managed implementation
of Apache Airflow, the orchestration tool
for big data pipelines and workflows.
To cover the machine learning requirements of the syllabus
we'll start with a high-level overview
of some machine learning concepts and terminology.
Then we'll look at TensorFlow Google's open source library
for deep learning applications.
Thankfully, we don't have to do all the heavy lifting
ourselves in GCP for machine learning
as next we'll look at Google's prebuilt machine learning
APIs for vision, video and language analysis.
Next up we'll look at how AutoML bridges the gap
between a fully ready solution
and building models from scratch.
In our next chapter,
we'll consider how you operationalize big data
and machine learning by deploying, monitoring,
and retraining models and pipelines.
And let's not forget security and regulation,
which are very important topics in the world of big data.
Here we'll go over the difference
between security and privacy
and the major regulatory frameworks
that might affect your data.
Finally, we'll do some preparation for the exam
with some reference architectures and a breakdown
of the exam guide.
Then with the course complete and a bit of luck,
you will book and pass the
Google Cloud Professional Data Engineer certification.
There's a lot of material to cover here
as the curriculum for the cert is so broad,
but don't panic.
Like I said, it'll be broken down into manageable chunks
and complimented with exam tips and hands-on labs
to help you reinforce your learning.
Now join me in the next video to find out if this course
really is for you and what you'll need to prepare.

```

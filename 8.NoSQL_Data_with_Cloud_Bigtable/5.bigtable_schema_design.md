## Resources 

- [Visualizing Cloud Bigtable Access Patterns at Twitter for Optimizing Analytics (YouTube)](https://www.youtube.com/watch?v=3QHGhnHx5HQ) 

## Lesson Transcript
```text
Hello, Cloud Gurus. Welcome to this
lecture, where we'll learn the most important
thing about Bigtable, how to design a good schema.
Let's look again at the example table we put together
for fictional public transport vehicles.
At the moment,
our row key is just the vehicle identifier itself.
So retrieving a row when we know that identifier,
will be quick and efficient,
but what if we want it to get all the vehicles
for a particular route, say route 86?
In SQL database, we might create a secondary index
for that column,
but there are no secondary indexes in Bigtable.
Instead we have to scan the entire table,
filtering results based on a regular expression match
to the string contained in that column cell.
This is the most time expensive way of querying Bigtable.
To help us improve on this,
we really need to think about query planning.
Query planning is fundamental to good schema
and row key design.
And it really just means thinking about what sorts
of questions we're going to be asking of our database.
In this example,
say we really want to get the data for all vehicles
that serve route 86.
In fact, we're unlikely to ever query data
for a single vehicle.
So in this query,
we already know the company and the route we're looking for.
We know this upfront,
this isn't information we're going to find out
by searching the database.
What we're looking for is the latitude and longitude
of each vehicle row.
This is the data we have to look up.
Well, if we already know the company
and the route number for a vehicle,
there's no benefit to storing in a column.
Instead, we can use a practice called field promotion.
Field promotion basically means,
taking data that we already know and moving it
into the row key itself
to help us create a better row key.
So now we have a row key design that gives us a couple
of different benefits.
We can still query this road directly using the key,
if we know the company and the route number
of a specific vehicle,
but we can also retrieve old data for vehicles on route 86
without having to scan the entire table.
Don't forget, rows are automatically sorted
lexical graphically.
So now we can use a row prefix filter
to return all the rows that start with the prefixes
"NYMT" and "86".
Bigtable doesn't have to scan the entire table
to find these rows,
depending on your application needs,
you can optionally include a timestamp
in your row key design.
While you can use the timestamp feature
of the cell data itself,
it's usually a better design to insert new rows
when new data is available.
In this example,
we've compromised and included a timestamp
that represents the nearest hour rounded down.
Then we'll store events within that hour
as timestamped cells.
Which way you go in this really depends
on how you need to query the data in your application.
And you should also bear in mind,
that repeatedly updating the same row
with new information is not as performant
as adding new rows.
Finally, a word of caution,
never put a timestamp at the start of a row key.
If all rows follow each other sequentially,
it's impossible to balance the load across your cluster.
So when designing a row key think about
what queries you'll run and how they can be optimized.
Queries will either use a specific row key,
a row key prefix,
or a combination of prefixes that ultimately return
a row range in the sorted table.
Some considerations for the components of a row key are:
Reversed domain names.
For example,
if you're storing multiple entries related to URLs.
Reversing the domain will keep rows
for the same websites closer together,
so they can be retrieved together.
String identifies.
Unique string identifies are usually good components,
because they lend themselves to natural distribution.
For example,
you'll applications usernames probably span most
of the alphabet in a reasonably uniform way.
So reads and writes should be evenly spread
across the table.
And timestamps, but only as part of a bigger row key design.
If you're struggling to find components for your row key
to make it uniformly distributed,
consider which fields in your columns could be promoted
to be part of the row key.
Some row key ideas to avoid are:
Domain names in the correct order, they may be distributed,
but reads are not going to be contiguous.
So it will be less efficient.
Sequential numbers.
These are a really bad idea
as your writes are always going to be on the end
of the table, rather than being distributed.
You should also avoid row key designs,
which will result in identifiers that end up
being frequently updated.
As we said before,
repeatedly updating the same row with new information
is not as performant as adding new rows.
And remember, as we've seen,
rows are assorted and grouped together,
so a real life entity can have numerous rows
that include a timestamp or some other meaningful identifier
whenever new data needs to be recorded.
Finally,
hashing values doesn't really add anything
in terms of distribution
If the original value is a string,
which should already be
alphabetically quite well distributed,
hashing will also make debugging harder
because you're obfuscating values with the hash.
So design your row keys for performance.
Remember, rows are lexical graphically sorted
as our columns within a column family.
So if your application needs to retrieve multiple entities
at a time, consider using a row key design
that will mean related entities will be stored
in adjacent rows.
We did this with our vehicles example
by using the route number in the row key.
Again, this design will help you balance reads
and writes evenly across your cluster.
Although, in practice it is hard to achieve completely
optimal distribution,
and you're bound to have a few minor hotspots,
but balanced access patterns are the way
to achieve linear scaling of performance.
That's why performance quotes for Bigtable are based
on a best case scenario of completely uniform distribution.
So you need to bear that in mind when designing the scale
of your clusters.
Designs for time series data
are often a bit different as well,
rather than use the wide column tables
we've been looking at.
Time series data often uses,
tall and narrow tables, where each row may contain a key
and possibly only a single column.
For time series,
it's always more efficient to use a new row
for every event stored rather than versioning cells
and continually updating the same rows.
With tall and narrow tables,
you should logically separate event data
into different tables where possible,
rather than try to accommodate lots of data
in a single schema design.
And although this is unlikely to come up in the exam
in practice, my advice is don't re-invent the wheel.
There are some great time series database systems
that run on top of Bigtable
where schema designs have already been proven in production.
For example, check out the OpenTSDB project.
Finally,
the main takeaway of all of this is to distribute work
across a cluster to avoid hotspots.
If one node has to work much harder than the rest
of your cluster,
you're going to introduce latency for a subset
of your queries.
You can avoid hotspots
by creating well-distributed row keys
using field promotion, as we've already looked at.
If you're really struggling
to make your writes non-contiguous,
consider adding a salted hash
to your row key that artificially distributes the rows,
your salt calculation should be based on the total number
of nodes, so you can achieve uniform distribution.
And finally, use Google's amazing Key Visualizer tool.
Rather than staring at metrics or just hoping for the best
this tool shows you a visual heatmap of CPU load,
based on a graph of your row key components over time.
It really is a game changer
for troubleshooting Bigtable performance.
In the resources section,
I linked to a video where Twitter described using this tool
to help them iterate over row key design
for their analytics project.
Okay, Cloud Gurus that about wraps it up for this lecture.
If you have any questions,
please let me know in the course forums,
and if not, I'll see you in the next video.

```

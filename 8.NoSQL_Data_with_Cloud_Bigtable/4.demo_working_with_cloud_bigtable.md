## Resources 

- [cbt Reference](https://cloud.google.com/bigtable/docs/cbt-reference) 
- [Cloud Bigtable Examples](https://github.com/ACloudGuru-Resources/Course_Google_Certified_Professional_Data_Engineer)

## Lab commands

```bash
*** HBase Shell Commands ***

create 'vehicles', 'loc', 'det'
list
describe 'vehicles'
put 'vehicles', 'M117-223', 'loc:lat', '40.781212'
put 'vehicles', 'M117-223', 'loc:long', '-73.961942'
put 'vehicles', 'M117-223', 'det:company', 'NYMT'
put 'vehicles', 'M117-223', 'det:route', '86'
scan 'vehicles'
get 'vehicles', 'M117-223'
put 'vehicles', 'M117-391', 'loc:lat', '40.780664'
put 'vehicles', 'M117-391', 'loc:long', '-73.958357'
put 'vehicles', 'M117-391', 'det:company', 'NYMT'
put 'vehicles', 'M117-391', 'det:route', '88'
scan 'vehicles'
scan 'vehicles', { COLUMNS => 'det:route', FILTER => "ValueFilter( =, 'regexstring:88')" }
scan 'vehicles', {ROWPREFIXFILTER => 'M117-2'}

*** Set up CBT ***

echo project = YOUR_PROJECT_NAME > ~/.cbtrc
echo instance = lab-instance >> ~/.cbtrc

*** CBT Commands ***

cbt listinstances
cbt listclusters
cbt ls
cbt ls vehicles
cbt read vehicles
cbt listappprofile labinstance
```

## Lesson Transcript
```text
Hello, Cloud Gurus and welcome to this lab.
Working with Cloud Bigtable in this lab,
we're going to dip our toes in the water by creating a Cloud
Bigtable instance. In doing so,
we'll take a quick tour of the instance creation options
inside the Google cloud console.
Then we'll interact with our new instance first with the
HBase shell,
and then with cbt Google's own command line tool for
Bigtable.
All you need to follow along with this lab is a GCP project.
As per usual,
we'll do everything we need to do inside the cloud console
and the Cloud Shell.
So get your project ready and let's get started.
So here we are in the GCP console,
Bigtable can be found in the storage section of the GCP
menu.
Let's create our first instance by clicking Create Instance,
enter an instance name of your choosing here.
I'm going to call mine lab instance.
The instance ID will be populated for you,
although you can change it if you want,
but bear in mind that these choices are permanent.
By default,
the instance type is set to production and the storage type
is set to SSD,
which as we learned is almost always the correct choice.
If we scroll down to our cluster section,
we can see the details for our first cluster it's named for
us. Although we could change that ID
if we wanted to. Choose a region and zone near to you,
I'm going to choose europe-west2 and europe-west2a by
default,
this production cluster has 3 nodes and the setup wizard
gives us a handy calculation of how performance this cluster
will be.
With 3 nodes we can expect reads or writes at 30,000
rows per second
with a 6 millisecond latency or table scans at 660
megabits per second.
These 3 nodes will be able to process storage of up to
7.5 terabytes together.
Although remember that data isn't stored on the nodes
themselves. Providing we use Bigtable properly,
we can expect this performance to scale linearly with the
size of our cluster.
So if we double the number of cluster nodes to 6,
we can see all of the performance metrics are doubled as
well,
including the total amount of storage the nodes can process.
Click Done for now, but don't worry,
we aren't actually going to create a cluster this size
now click Add Replicated Cluster.
We can now add a second cluster to our instance,
and this is how we achieve high availability and automatic
fail-over.
We're free to choose a completely different region and zone
for this cluster,
but ideally we should locate this in the same region as our
first cluster so we're
not increasing the latency of replication or paying
additional egress charges,
but we can choose a different zone to give us some
redundancy.
So let's click Done here and marvel at our super powerful
Bigtable cluster.
We'll scroll up to the handy cost estimator and wow,
this is looking quite pricey, nearly $10 an hour.
This seems like a lot, but we've configured a cluster
that's probably big enough to run our own social network.
We don't need anything so big for our lab.
So the first thing to do is change this instance type to
development.
We could always upgrade this to production later,
but for now,
this will give us a cheaper single node cluster.
We can see this has updated our cluster preferences for us.
And if we look at the cost estimator again,
the total is dropped right down.
Now we're just looking at just over a dollar an hour,
which is about how long it should take to do this lab.
So now we're happy that we're not going to break the bank.
Click Create
the console takes you back to the Bigtable instances page
and in just a few seconds, the instance is ready.
That's because Bigtable,
isn't relying on compute engine VMs.
It's an internal managed service
the Google uses themselves and we're just reserving some
space on it.
Let's click on our instance and take a closer look.
There's not much to see here yet,
but the monitoring page will show us a good overview of the
health of our instance once we're actually using it.
Now let's open Cloud Shell so we can use some command line
tools to interact with our Bigtable instance.
I'm going to full screen the Cloud Shell and enlarge my font
to make it easier for you to follow along.
Make sure you have your project ID set correctly here.
If you don't,
you can update it with gcloud config set project and the
name of your project.
So we're going to use the HBase command line tool to talk to
our Bigtable instance,
setting this up requires Java, Maven, and some other
configuration.
But luckily Google have created a script that does all this
for us.
So first we'll clone Google's Bigtable examples, repo.
You can grab the link for this from the resources section.
Once that's cloned change into the Cloud Bigtable
examples directory, and then into the Quickstart directory,
then run ./quickstart.sh
that error is nothing to worry about and you can safely
ignore a lot of the other messages that come up now as well.
The script will pick up your project ID and the instance
you've created because there's only one in your project
after downloading and compiling some dependencies,
the script will drop you into the HBase shell.
And there we are.
You might see a lot more downloads and activity than this in
your console
as it takes a bit longer to set up the first time you use
the Quickstart script. Just pause the video here
if you need to until you get the HBase shell prompt.
So first let's create a table for the vehicles data we were
looking at in our last lecture. To create a table,
we use the command create followed by the table name
and the names of our column families,
which we'll shorten for simplicity to LOC for location and
DET for details.
We can use lists to show us our tables.
And if we use describe vehicles,
it will show some more detailed information about this
table.
Now let's put some data into our table.
We do this with the put command followed by the name of the
table, a row key
that we choose, the column
which takes the format of the column family, a colon,
and then the column name or qualifier, and finally the
value. Using the HBase shell interactively
like this means we have to enter each cell individually.
So this can take quite a bit of time.
I've put all of these commands into a text file that you can
download from the resources section.
So feel free to copy and paste
once you're familiar with the command,
I'm going to enter the data for the remaining 3 cells in
this row.
And now we finally have a complete row in our table.
Let's scan the table to see it with scan vehicles. We
could also retrieve that row on its own by using its row key
with get vehicles and the row key.
Notice how each cell contains a timestamp of when it was
written.
Okay, let's add data for one more vehicle.
Bear with me while I type this in again,
you can feel free to copy and paste.
Now we have 2 rows in our table.
Let's scan our table again, looking good.
So we know how to retrieve a robot's individual key,
which will be the fastest type of operation.
But we need to think about what sort of queries we need to
run on this data. What do we already know?
And what are we looking for?
Say, for example,
we want to extract the location data for a specific route
that may have multiple vehicles.
We already know the route number,
and we want to retrieve all the latitudes and longitudes. We
could add a filter to our scan so that it only returns
results for a specific route. It's fiddly,
but we can use scan vehicles and add this qualifier.
We'll look inside the column,
DET:route and add a filter,
which is a regular expression string looking for the string
88.
This will return the row key of any rows that match that
regular expression.
But we had to do a full table scan to get this information
scanning the entire table when it contains thousands or even
millions of rows is going to take a super long time.
It's the kind of operation you want to avoid wherever
possible.
So what else can we do?
Remember the only index on our table is on the row key,
but it turns out we can scan on partial matches of our row
key with, for example, scan vehicles and a row prefix
filter. So if we had multiple vehicles that all started with
this prefix, they would all show up here.
The trick is to put as much of the information you already
know into your row key so it can
be indexed. Exactly how you do this is the most
important feature of your Bigtable instance that you'll
design.
So we'll cover all the details in our next video. For now
let's quit out of the HBase shell with control C and we'll
take a quick look at Google's native alternative for
connecting to Bigtable cbt. First let's type cd to change
back to our home directory and clear the screen.
We need to create a file called cbt RC,
that the cbt tool will use.
It only contains 2 lines so we can create it with echo.
The first line is our project.
Make sure you use your project here.
The second line is the name of our Bigtable instance,
which I called lab instance.
And I'm just remembering I didn't include a hyphen.
Your cbt RC file should now look like this.
With that file in place,
we can now run simple cbt commands straight from the command
line.
cbt is more geared towards interacting with Bigtable the
service,
whereas HBase was all about manipulating the data itself as
a client.
We can view our Bigtable instances with cbt list instances,
and we can see our clusters with cbt list clusters.
We can view tables with cbt ls.
We can also use ls to see more information about a table,
including its column families with cbt ls vehicles.
And we can view data with cbt read vehicles,
But as I said,
you would normally interact with data through HBase or a
client library in your application.
cbt is also helpful for working with application profiles
from the command line. Let's type cbt list app profile,
and the name of our instance,
and here's our default application profile routing to our
single cluster and allowing transactional writes.
Okay. Cloud Gurus,
we're off to a great start,
but it's time for more theory. To tidy up this lab,
simply go back to the cloud console,
go to the instance details page and click Delete Instance
and to the instance, name to confirm and click Delete.
Don't forget this step.
Or even though it's a development instance,
you still may run up quite a big bill.
If you have any questions about this lab,
please let me know in the course forums.
And when you're ready, I'll see you in the next video.

```

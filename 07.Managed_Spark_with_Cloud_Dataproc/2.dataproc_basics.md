## Lesson Transcript
```text
Welcome back, Cloud Gurus.
In this lecture,
we'll go over the basics of using cloud Dataproc,
including setting up clusters and submitting jobs.
There are a couple of design choices to make
when creating a Dataproc cluster.
And the first one,
is whether to create regional or global resources.
If you choose regional,
you can isolate all the resources used for Dataproc
into a specific region,
such as, us-east1, or europe-west1.
You may need to do this for a variety of compliance
or performance reasons.
When you specify a region,
you can then choose the zone yourself
or have Dataproc pick one for you.
Alternatively, you can choose global.
This doesn't actually mean
your cluster is automatically a global resource.
It just means that it's not tied to a specific region
and you can place its resources
in any available zone, worldwide.
Next up, you have 3 different types of clusters
that you can build.
A single node cluster is just that.
A single VM that will run the master and work the processes.
Single nodes can still provide
most of the features of Dataproc.
You're obviously just limited to the capacity of a single VM
and you can't auto scale a single node cluster.
A standard cluster is your next
and probably most likely option.
This comprises a master VM,
which runs the YARN Resource Manager and HDFS Name Node,
and 2 or more worker nodes,
which each provide a YARN Node Manager and HDFS Data Node.
The type of each of these machines is fully configurable,
as is the amount and type of disk you provide to them.
With a standard cluster,
you can also add additional preemptible workers.
This is sometimes useful for large processing jobs.
But in addition to the usual caveats
about using preemptible VMs,
bear in mind that they also can't provide storage for HDFS.
For long running Dataproc clusters,
where you need to be able to guarantee reliability,
your final option is a high availability cluster.
This is similar to a standard cluster,
except you now get 3 masters,
with YARN and HDFS configured to run
in high availability mode,
providing uninterrupted operations
in the event of any single node failure or reboot.
Once your cluster is up and running,
you have lots of options for how to submit jobs.
You can submit jobs using the gcloud Command Line tool
from either your own computer or within cloud shell,
from within the GCP Console,
using the cloud Dataproc HTTP API,
or you can even SSH into the Master Node
and submit a job locally.
Dataproc will accept several different types of job,
Hadoop, Spark, SparkR, Hive, Spark SQL, Pig, Presto,
and PySpark.
Each will have their own subset
of parameters and arguments that you can provide,
such as the main program to run,
and any additional files or properties required.
Jobs are created in a pending state,
then move to a running state
while they're being processed by the Dataproc agent
and the YARN cluster.
When a job is complete, it enters the done state.
These states can be queried by the Dataproc API
or simply viewed in the GCP console.
Stackdriver monitoring can be used to monitor
the health of your Dataproc cluster.
Notable Stackdriver metrics for Dataproc include
allocated memory percentage,
which will show you how much of your overall cluster memory
is being used by the current workload,
storage utilization,
which will show you how much
of the total available HDFS storage you have used,
and unhealthy blocks,
which should help you to identify any problems you may have
with your storage.
YARN and job output logs can also be redirected
into Stackdriver logging for later inspection.
OK Cloud Gurus, I think that's enough theory for now,
but if you have any questions,
please let me know in the course forums.
Next up, it's time to get our hands dirty
with our first Dataproc lab.

```

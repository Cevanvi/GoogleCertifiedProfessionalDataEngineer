## Lesson Transcript
```text
Hello Cloud Gurus.
In this video,
we'll be taking a look at some
of the common neural network architectures.
Being somewhat familiar with the basic architectures,
can make the topic of deep learning much less intimidating.
So, let's take a look.
Let's start with feed-forward neural networks.
These are the simplest and the most common type
of deep neural network.
They also have many applications.
They were the first type of deep neural network to be used,
and they have the typical structure
we've already discussed,
an input layer and output layer
and a varying number of hidden layers.
Typically,
there are also a number of non-linear activation functions
that are applied.
In these networks,
information flows in one direction only.
That is, forward.
There are no cycles or loops.
You can think of feed forward neural networks
as being the basic type of deep neural network.
Next we have recurrent neural networks.
The flow of information through a recurrent neural network,
does form cycles or loops.
This is unlike the feed forward networks
we've just discussed.
Recurrent neural networks have directed cycles
where following the flow of information,
may result in arriving back at your starting point.
Recurrent neural networks can be very difficult to train
due to the complicated dynamics that result from the cycles.
There are many different types of recurrent neural networks.
In this example,
we can see that the output can also be used as input
to the neural network.
It is often the case that the directed cycles
will occur within the neural network.
That is, not necessarily between the output
and input layers.
Next we have convolutional neural networks.
A convolutional neural network is a type of neural network,
which is most often used to perform visual learning tasks.
They're used widely in image and video recognition,
in image classification,
as well as in natural language processing.
Convolutional neural networks consist of an input layer,
an output layer and a varying number of hidden layers.
The hidden layers in a convolutional neural network
contain a number of convolutional layers.
We often have a pairing of a convolutional layer
with something which is known as a pooling layer.
We'll look at pooling layers in the next slide.
Convolutional layers summarize features in an input image.
Convolutional neural networks apply filters or kernels
that are smaller than the image being processed.
These filters are systematically applied
over the entire image.
This allows features to be identified anywhere on an image.
There'll be an example of a convolutional neural network
in the labs.
Pooling layers simplify inputs.
This is known as downsampling.
In a convolutional neural network,
pooling layers will often succeed a convolutional layer
after a non-linear activation function has been applied.
There are 2 different types of pooling.
There is average pooling where we calculate
the average value for each patch on the feature image.
And there is also maximum pooling or max pooling,
which calculate the max value for each patch
that we look at.
A common pooling feature,
is a 2x2 pixel filter with a stride of 2 pixels.
Let's look at this example image,
which is 6x6.
That is,
there are 6 pixels in the horizontal plane
and 6 pixels in the vertical plane.
And let's apply a 2 by 2 filter.
The filter covers 4 pixels.
If we are doing average pooling,
we'd take the average value of these 4 pixels
and place it in the output.
If we were doing a max pooling,
we would take the maximum value of those 4 pixels
and place it in the output.
If we have a stride of 2 pixels,
we will move the filter along by 2 pixels.
Again, we would apply the average pooling
or max pooling operation to determine our output value.
We would repeat this procedure
until the entire input image has been processed,
and we have our output image.
As you can see here,
the filtering operation has halved the number of pixels
in the vertical and horizontal planes.
So, we've gone to a 6x6 to a 3x3.
Let's finish off
by considering generative adversarial networks or GANs.
GANs are deep neural networks
that are composed of 2 separate networks.
These 2 networks have an adversarial relationship.
GANs are of great interest at the moment
because they are able to be creative.
They can create images, music, speech, and poetry.
GANs can be used to create deep fakes.
The generator network,
or the one network will generate images
that are used to try and fool the discriminator network.
The discriminator network,
which has been trained on real images,
will look at the generated images
and try and predict whether they are generated,
or they are real.
So, the discriminator network
will predict a label, real or fake.
The output of the discriminator network
is in a feedback loop with the generator network.
This allows the generator network
to know how well it is doing
Okay Cloud Gurus,
that was a very high level overview
of some of the most important neural network architectures.
I hope you found the video informative.
I'll see you in the next video.
```

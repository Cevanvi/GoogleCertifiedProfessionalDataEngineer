## Resources 

- [Regularisation](https://codeburst.io/what-is-regularization-in-machine-learning-aed5a1c36590) 
- [L2 Regularisation](https://developers.google.com/machine-learning/crash-course/overfitting/regularization) 
- [Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course/) 
- [ML Terminology](https://developers.google.com/machine-learning/intro-to-ml/supervised) 
- [Worked gradient descent example](https://www.kdnuggets.com/2017/04/simple-understand-gradient-descent-algorithm.html) 


## Lesson Transcript
```text
Welcome back, Cloud Gurus.
In this video,
we'll cover some of the core concepts
and ideas in machine learning
that allow Machine Learning Models to be trained.
There is a small amount of maths.
Even if you hate maths, I promise you you'll survive.
Let's get going.
So what is a Machine Learning Model?
We normally start with data of some sort
and from that data we want to obtain some sort of answer.
And the way that we do that
is with a Machine Learning Model.
The data is normally fed into the model
and out of the model, we get the answers that we want.
It's important to note that the model obtains the answers
by inferring a set of rules from the data
that's used to train it.
So let's take as an example, the number 3.
We want the answer 6.
What we could do is create a really simple model.
We take 3 as an input, multiply by 2 to give us six.
In this case, our rule is to multiply the 3 by 2,
so the incoming number by 2,
and what we have just constructed here is a model.
Of course,
there are many different ways of deriving 6 from 3,
but this would give us a different model.
And then we can take different models
and evaluate them on our input data.
Let's now look at the Machine Learning Pipeline.
So there are 3 phases.
We have the Data Preparation phase,
the Model Training phase,
and then the Operating phase.
So we have raw data as input.
The raw data is generally cleaned and processed in some way,
so that it's ready for training.
Once that's done,
the processed data is split
into training data and testing data.
The training data is used as input to our untrained model.
The model that we train is then evaluated
against the test data
to determine how well it inferred rules
from the training data.
Once we have the trained model,
it is normally deployed to Production.
The trained model can then be used
to make real-time predictions.
So for example,
the model could be used to predict
which product a particular customer is most likely to buy
when they're on the website.
The trained model can also be used
to perform batch predictions.
These are normally offline predictions
where many predictions are made
in a very short period of time.
It's worth noting that over time
trained models become less and less effective
and they normally need to be retrained
and so they go back into the training phase.
Let's now take a look at Features and Labels.
So, what is a label?
A label is something that is of particular interest to us.
So this could be, for example, the price of houses.
We normally denote labels with y.
A feature, on the other hand, is some sort of attribute
that is associated with the label
and has some sort of relationship with the label.
So when we think of houses,
features could be things like the size of the house,
the number of rooms, where the house is located, et cetera.
Features are normally denoted with an x.
So each feature could be labeled differently,
such as x1, x2, x3, x4, et cetera.
Examples are generally considered to be features
together with labels.
And of course we can have multiple examples.
So each house here with its information on the features,
as well as its house price, would form a single example.
A labeled example specifically
has a label associated with a set of features.
So for example,
where we have the features size, number of rooms, location,
it will then have a house price that is the label
associated with that set of features,
that is for that particular example.
And here we have our features x1, x2, x3, x4,
and they map onto label y.
Finally, we can have unlabeled examples.
Unlabeled examples is where
we have the set of feature values,
but we don't have the label value.
That's denoted here by the x's
that don't have an associated y or label value.
We normally want to predict the label value
for unlabeled examples.
Instead of naming the predicted labels y,
we normally name them something else, such as y prime.
We're now going to look at Curve Fitting.
If you think back to your high school maths,
you will probably remember the Cartesian plane,
which has an x-axis and a y-axis.
These are perpendicular to each other.
Suppose we have a single feature,
which is the size of a property,
and let's associate our y-axis with our label
or house price.
Suppose we have a set of labeled examples.
We can then plot these on this plane.
Now if you remember
the equation for a straight line is normally y = m(x) + c,
where m is the gradient of your line
and c is the intercept with the y-axis.
If we set m, the gradient, equal to 0,
then we have y = c.
And if we set that to a particular value, such as c1,
you can see, we have the horizontal line y = c1.
This line doesn't seem to fit our data very well.
If we set m, the gradient, equal to 1
and c equal to 0,
we have y = x,
which is a straight line that goes through the origin.
In this instance,
y = x seems to capture the nature of our data points
better than y = c1.
Let's consider a general scenario.
We'll set the gradient, m, equal to m2
and a constant equal to c2,
and that is a line that does not go through the origin.
In this case,
the line would have a gradient of value m2
and a y-intercept value of c2.
This last line seems to fit our data
better than the other two lines.
So let's take a look at the model parameters.
So we had a straight line,
which was given by the equation, y = mx + c.
This allows us to calculate a y-value for a given x-value,
where m and c are specified.
So m could be 2 and c could be 1.
In this case, for point x = 1,
We would have 1 x 2 + 1, which is equal to 3.
So where x is equal to 1,
y would be equal to 3.
We can simply change the names of m and c
to w1 and w0, respectively.
And then instead of saying y,
we can use the function notation to say we have F,
which is a function of x,
which is equal to w0 + w1x.
This is exactly the same equation
we had for the straight line.
It's just written in a different form.
Now we can also consider F to be a function of w0 and w1,
in addition to x.
If we fix w0 and w1, we have a specific line.
However, we can vary those values
as we did on the previous slide.
So in the bottom equation, we have x, which is a feature,
we have 2 weights w0 and w1,
and F will basically be the calculated value
for our label for the value X.
We're now going to look at the concept of loss
and how we measure it.
Suppose we have the same data points we had previously
with each one being given by an x and a y value.
Here, we have 7 data points.
Suppose we try to fit a straight line to this data.
How do we know how good this line is?
Let's look at what happens at the x value, x7.
We have the actual value given by (x7,y7)
and then the predicted value at x7, which is (x7,y7' prime).
Clearly, these are not the same.
We have a difference between the two points
shown by the red line.
So how different are the points?
We can calculate this by taking the difference
between y7 and our calculated value y7' prime.
That gives us the difference between our predictive value
and the actual value at x7.
Now we can do the same for all the other data points
and determine the difference between the predicted values
and the actual values.
Let's look at this from another perspective.
So suppose we have 2 data points, (x1,y1) and (x2,y2).
The best line that we can fit to this data
is a straight line that goes through both points.
And in this case, it's horizontal.
Consider another line
that doesn't fit the data particularly well.
Let's do what we did in the previous slide
and calculate the difference.
So we have (x1,y1) and the predicted point (x1,y1' prime).
For x2, we have (x2,y2) and we have (x2,y2' prime).
The difference at point x1 is given by y1 - y1' prime,
which is what we had previously.
And that's clearly greater than 0,
because y1 is greater than y1' prime.
If we do the same at x2 and calculate y2 - y2' prime,
we find that it is less than 0.
Suppose we wanted to sum all the errors
to see how closely our line fits the actual data.
If we take the loss to be the sum of the two values
that we calculated,
because on this diagram
they're more or less the same length,
we have a loss of 0.
This is because the positive value
and the negative value offset each other.
What we rather want to do
is take the loss to be the square of the values
or the square of the differences of the actual y value
and the predicted y value at each point.
If you have a look here,
you will now see that the loss is much greater than 0,
which is exactly what we want.
This is because the purple line
doesn't fit the data particularly well
and so the loss should be greater than 0.
The Mean Squared Error is a specific type of loss measure.
What we have in this part of the equation
is exactly what we saw on the previous slide.
We simply summing all the differences
between the actual label values
and our predicted label values.
We're squaring that, and as I said, we're summing it.
We're then dividing that by the number of data points
that we have.
So instead of just summing the value of the squared errors,
we are now finding the mean of that value,
which is exactly why this loss function is called
the mean squared error.
So once we've selected a line and we've measured the error,
how do we improve the line?
How do we find a line that better fits the data?
We do this using a process of optimization.
We'll look at a specific type of optimization now,
very briefly called gradient descent.
Consider a very simple line
where we've set the y-intercept to 0, so we have y = wx.
We have a single weight called w.
Because our line is a function of w
this implies that our loss function,
the mean squared error,
is also a function of w.
If you look at the graph here,
we have w on the horizontal axis,
and loss, or the mean squared error, on the vertical axis.
Here, I've plotted the loss function
for all values of w within some range.
Suppose we randomly choose a value of w1 for our weight.
At the point w1, you can see that if we move to the left,
the loss is increasing,
and if we move to the right, the loss is decreasing.
So from point w1, how do we know how to proceed?
Well, we calculate something called the gradient.
I'm not going to go into the details of it,
but the gradient gives us the direction
in which the loss function increases.
So, as we said, it increases going to the left.
The gradient is denoted by this triangle.
So if we move to the left, our loss is increasing.
We want to move in the direction
where the loss function decreases.
So that's over to the right.
How do we find that direction?
We simply take the negative value
of the gradient that we calculated.
If we move some distance
in the direction of the negative value of the gradient,
we get a new point, w2.
As you can see,
the value of the loss function at w2
is less than the value of the loss function at w1.
Again, the gradient tells us that if we move to the left
we will increase our loss function.
We want to decrease it,
so we move in the opposite direction,
which is the negative of the gradient.
If we move a bit in that direction
that gives us a new point, w3.
Again, the loss functions value at w3
is less than it was at w2.
We, again, take the gradients,
and again, if we move to the left, it increases,
if we move to the right, it decreases.
We can continue this process
until we find the minimum value for w,
which is where the loss function has its lowest value.
This is the w we select.
If we use this minimum value
for y in our straight line function, y = wx,
we will have the line that best fits our data.
That is where the loss is at a minimum.
The distance that we moved with each step
along the horizontal axis
in the opposite direction of the gradient
is normally known as the learning rate.
I should mention that I have left out some details
in order to make this easier to understand.
I should mention that there are other ways
to optimize the loss function, that is, to minimize it.
Gradient descent is just one way to do this.
There is a variant of gradient descent,
which is commonly used,
which is called stochastic gradient descent.
It is very similar to gradient descent.
That's it for this video.
I hope you enjoyed it.
I know it got a bit hairy near the end,
but it will be easier going from here.
See you in the next video.
```

## Resources 

- [Early stopping](https://machinelearningmastery.com/early-stopping-to-avoid-overtraining-neural-network-models/) 
- [Cross validation](https://machinelearningmastery.com/k-fold-cross-validation/) 
- [Regularisation](https://codeburst.io/what-is-regularization-in-machine-learning-aed5a1c36590) 

## Lesson Transcript
```text
Welcome back Cloud Gurus.
In this video, we'll be covering Overfitting.
Overfitting has absolutely nothing to do
with how well you fit into your pants.
Overfitting is a common challenge that has to be overcome
when training machine learning models.
Let's jump in.
Here have a plane with 2 axes.
We have a horizontal axis,
which is the complexity of our model.
And we have a vertical axis,
which again is our loss function.
In general, the more complex we make our model,
the better it will fit our training data.
So we can get the error on our training data,
very, very close to 0.
Which you can see here as the green curve approaches
the horizontal axis.
The validation set is used
to determine how well our training is going.
We will often have a validation curve
that looks similar to this.
We can see that as the model starts increasing complexity
from 0, the loss on the validation set,
decreases fairly steadily.
However, there is a point where it starts increasing
with model complexity.
So when we're far over to the left,
we want to move further to the right.
And when we're really far over to the right,
we want to move further to the left.
And there's a natural point where the loss
of the validation set is minimal.
So when a model is on the left side of this,
we say the model Underfits the data.
Where we enter the range where the validation error
is increasing with increasing complexity.
We say that we have Overfit the model.
Where our validation error is minimal,
is where we have a balanced model,
which represents the correct level of complexity.
Let's look at Overfitting from a curve fitting perspective.
This may clarify anything you didn't understand
from the previous slide.
Here we have 3 diagrams, all with the same set
of data points.
Let's look at the difference between Underfit,
Balance, and Overfit.
An Underfit model would be something like a line.
It doesn't seem to capture the underlying structure
of our data.
A balanced model on the other hand is a model
or curve which fits the data very well.
However, it is not overly complex.
It is still somewhat simple.
The shape here is a simple parabola.
In the Overfit case,
we can see that the curve fits the data very, very well.
It fits it far better than in the other 2 cases,
the Underfit and even the Balance case.
Let's see what happens when we add
a new hypothetical data point.
This would be for example, an unseen example.
In the Underfoot case,
there is a fairly large distance between
the new data point and our curve.
Which means we didn't fit it very well.
In the balance case, the new point is relatively close
to our curve.
Which means we predicted its value fairly well.
In the Overfit case,
we can see that if we take a horizontal line between
the new data points and our curve,
it's a very large distance.
This is the problem with Overfitting.
It fits the training data very, very well,
but it does not handle new data
or unseen data well at all.
We say that an Overfit model does not generalize
because it does not generalize to new data.
So how do we stop Overfitting from happening?
One way to do this is known as regularization.
They are other ways.
We'll take a look at these a little later.
So firstly, with training,
we want to minimize the loss of the model that we create
and that we train using our data sets.
The regularization term is a new term that measures
the complexity of our model.
There are 2 types of regularization.
There is the L2 regularization term,
where we take the sum of the squares of all of our weights.
Then there is the L1 regularization term.
This is where we sum the absolute values
of all of our weights.
With regularization, we now add in a new term
into the equation we're trying to minimize.
That is the regularization term,
which would be L1 regularization or L2 regularization.
The Lambda that appears before the regularization term
is known as the regularization rate.
If Lambda is small,
the effect of regularization is relatively small.
If Lambda is large,
then the regularization factor is much increased.
The important thing to understand is that adding
the regularization term means that our model will generally
be simpler than it would have been without it.
This tends to prevent Overfitting.
So, as we said, there are 2 types of regularization.
There is L1 regularization and L2 regularization.
L1 regularization,
penalizes the absolute values of the weights.
The effect of this is to drive weights
of noncontributing features towards 0.
This results in sparse matrices.
L2 regularization penalizes the square
of the weights.
Because of this, it tends to drive all
the weights towards 0.
So our model is considered simpler
when our weights have lower values.
Now there are a number of ways to avoid Overfitting.
Firstly, there's regularization, which we've just discussed.
Next, we can increase the training data by having more data.
Our train model is more likely to generalize well.
We can also use feature selection to include more features
or to reduce the number of features that are available.
Certain features may make it very easy
for the model to Overfit.
And in some cases it might be a good idea
to remove these particular features.
Another approach to avoid Overfitting is
to do what is known as early stopping.
This means you don't allow the model to train for too long.
You only allow it to train on a certain number of iterations
so that it can't fit too well to the training data.
Cross validation is another approach to avoid Overfitting.
Cross validation is where we take our training data
and split it into much smaller training sets.
These sets are then used in different ways to tune a model.
These smaller sets on known as folds.
This gives us the term K fold cross validation.
Where K is the number of folds or smaller sets
into which our training data is divided.
Finally, in neural networks, we can add dropout layers.
These are layers where essentially the weights
are occasionally all set to 0.
This is great for avoiding Overfitting of neural networks.
Okay, Gurus.
I hope you enjoyed that section.
I know it was quite challenging.
I will see you in the next video.
```
